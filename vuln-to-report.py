import os
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from collections import defaultdict
from docx import Document

# Load vulnerability database from NVD API
cve_db = defaultdict(list)
nvd_api_url = "https://services.nvd.nist.gov/rest/json/cves/1.0"
params = {
    'resultsPerPage': 2000,
    'startIndex': 0
}

def fetch_cve_data():
    try:
        response = requests.get(nvd_api_url, params=params)
        if response.status_code == 200:
            cve_data = response.json().get('result', {}).get('CVE_Items', [])
            for cve in cve_data:
                cve_info = cve.get('cve', {}).get('CVE_data_meta', {})
                cve_id = cve_info.get('ID')
                description = cve.get('cve', {}).get('description', {}).get('description_data', [{}])[0].get('value', '')
                impact = cve.get('impact', {}).get('baseMetricV3', {}).get('cvssV3', {}).get('baseScore', 'N/A')
                cve_db[cve_id].append({
                    'id': cve_id,
                    'summary': description,
                    'version': impact  # Using baseScore as a proxy for version/impact
                })
        else:
            print("Failed to fetch CVE data from NVD API.")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching CVE data: {e}")

fetch_cve_data()

# Define a function to fetch payloads from a URL or local file
def fetch_payloads(source_url=None, local_file=None):
    payloads = []
    try:
        if source_url:
            response = requests.get(source_url)
            if response.status_code == 200:
                payloads = response.text.splitlines()
        elif local_file:
            with open(local_file, 'r') as file:
                payloads = file.read().splitlines()
    except Exception as e:
        print(f"Error fetching payloads: {e}")
    return payloads

# Fetch XSS payloads from a remote repository (PayloadAllTheThings)
xss_payloads = fetch_payloads(source_url='https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/XSS%20Injection/Intruder/xss-payloads.txt')
# Fetch RCE payloads from a remote repository (PayloadAllTheThings)
rce_payloads = fetch_payloads(source_url='https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/Command%20Injection/Intruder/command-injection.txt')

# Define a function to scan a website for vulnerabilities
def scan_website(target_domain):
    vulnerabilities = defaultdict(list)
    try:
        response = requests.get(target_domain)
        soup = BeautifulSoup(response.content, 'html.parser')
        scripts = soup.find_all('script')
        for script in scripts:
            src = script.get('src')
            if src:
                src_url = urljoin(target_domain, src)
                parsed_url = urlparse(src_url)
                if parsed_url.netloc:
                    # Check for known vulnerabilities in JavaScript libraries
                    lib_name = os.path.basename(parsed_url.path)
                    if lib_name in cve_db:
                        for cve in cve_db[lib_name]:
                            vulnerabilities[cve['id']].append({
                                'library': lib_name,
                                'version': cve['version'],
                                'description': cve['summary']
                            })
        # Check for SQL injection vulnerabilities
        forms = soup.find_all('form')
        for form in forms:
            action = form.get('action')
            if action:
                action_url = urljoin(target_domain, action)
                test_url = action_url + "?test=' OR '1'='1"
                response = requests.get(test_url)
                if 'error' in response.text.lower():
                    vulnerabilities['SQLi'].append({
                        'url': action_url,
                        'parameter': 'test',
                        'description': 'SQL injection vulnerability detected'
                    })
        # Check for cross-site scripting (XSS) vulnerabilities
        inputs = soup.find_all('input')
        for input in inputs:
            name = input.get('name')
            if name:
                for payload in xss_payloads:
                    response = requests.get(target_domain, params={name: payload})
                    if payload in response.text:
                        vulnerabilities['XSS'].append({
                            'url': target_domain,
                            'parameter': name,
                            'description': 'Cross-site scripting vulnerability detected'
                        })
                        break
        # Check for Remote Command Execution (RCE) vulnerabilities
        for form in forms:
            action = form.get('action')
            if action:
                action_url = urljoin(target_domain, action)
                for payload in rce_payloads:
                    test_url = action_url + "?cmd=" + payload
                    response = requests.get(test_url)
                    if 'uid=' in response.text or 'root:' in response.text:
                        vulnerabilities['RCE'].append({
                            'url': action_url,
                            'parameter': 'cmd',
                            'description': 'Remote Command Execution vulnerability detected'
                        })
                        break
    except requests.exceptions.RequestException as e:
        print(f"Error scanning {target_domain}: {e}")
    return vulnerabilities

# Define a function to generate a Word document report
def generate_report(vulnerabilities, target_domain):
    doc = Document()
    doc.add_heading(f'Vulnerability Report for {target_domain}', 0)

    for vuln_id, vuln_list in vulnerabilities.items():
        doc.add_heading(vuln_id, level=1)
        for vuln in vuln_list:
            if 'library' in vuln:
                doc.add_paragraph(f"{vuln['description']} ({vuln['library']} {vuln['version']})")
            else:
                doc.add_paragraph(f"{vuln['description']} (URL: {vuln['url']}, Parameter: {vuln['parameter']})")

    # Save the document to the downloads directory
    download_dir = os.path.join(os.path.expanduser('~'), 'Downloads')
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
    report_path = os.path.join(download_dir, f'{target_domain.replace("http://", "").replace("https://", "").replace("/", "_")}_report.docx')
    doc.save(report_path)
    print("Report saved to", report_path)

# Scan a website and generate a Word document report
target_domain = input("Enter the domain you want to target")
vulnerabilities = scan_website(target_domain)
generate_report(vulnerabilities, target_domain)
print("Report saved to the Downloads directory")
